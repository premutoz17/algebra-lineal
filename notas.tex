\documentclass{book}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[mathscr,mathcal]{euscript}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{shapepar}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{color}
\usepackage{shapepar}
\newtheorem{theorem}{Teorema}
\newtheorem{proposition}{Proposición}
\newtheorem{definition}{Definición}
\newtheorem{axiom}{Axioma}
\newtheorem{corollary}{Corolario}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem*{remark}{Remark}

\title{Notas de Álgebra Lineal}
\author{Carlos Francisco Flores Galicia.}
\date{}

\begin{document}

\maketitle

\chapter{Espacios vectoriales}
\subsection{Espacios vectoriales}
\subsection{Subespacios vectoriales}
\subsection{Combinaciones lineales}

\begin{definition}
Sea $V$ un espacio vectorial y $S \subseteq V$, $S \neq \emptyset$. Se dice que un vector $v \in V$ es combinación lineal de elementos de $S$, si existe un conjunto finito $\{s_1,s_2,...,s_n\}\subseteq S$ y escalares $\lambda_1,\lambda_2,...\lambda_n \in K$ tales que $v=\lambda_1 s_1+\lambda_2 s_2+...+\lambda_n s_n$. Se dice también que $v$ es combinación lineal de $\{s_1,s_2,...,s_n\}$.
\end{definition}

\begin{definition}
Sea $V$ un espacio vectorial y $S=\{ s_1,s_2,...,s_n \} \subseteq V$. Definimos al conjunto generado por elementos de $S$ como

\begin{equation}
\langle S \rangle = \{\lambda_1 s_1+\lambda_2 s_2+...+\lambda_n s_n : \lambda_1,\lambda_2,...\lambda_n \in K \}
\end{equation}

Esto es, el conjunto generado por $S$ es el conjunto de todas las combinaciones lineales de los elementos de $S$.
\end{definition}

\begin{definition}
$\langle \emptyset \rangle=\{0_V\}$
\end{definition}

\begin{theorem}
Sea $V$ un espacio vectorial y $S \subseteq V$, $S \neq \emptyset$, entonces $\langle S \rangle \leq V$ y $\langle S \rangle$ es el subespacio de $V$ más pequeño que contiene a $S$ (es decir, que $\langle S \rangle$ es un subconjunto de todos los subespacios de $V$ que contienen a $S$).
\end{theorem}
\begin{proof}
Probemos primero que $\langle S \rangle \leq V$. Como $S \neq \emptyset$, al menos $0_V \in \langle S \rangle$. Luego, sean $u,v \in \langle S \rangle$, por tanto $u$ y $v$ son combinaciones lineales de elementos de $S$, de manera que existen $s_1,s_2,...s_n,t_1,t_2,...,t_n \in S$ tales que $v=a_1s_1+...+a_ns_n$ y $u=b_1t_1+...+b_nt_n$, con $a_1,...a_n,b_1,...,b_n \in K$. Ahora bien, es claro que $v+u=a_1s_1+...+a_ns_n+b_1t_1+...+b_nt_n$ y $cu=cb_1t_1+...+cb_nt_n$ pertenecen a $\langle S \rangle$, para cualquier $c \in K$. Por lo tanto $\langle S \rangle \leq V$.\newline \newline
Por otra parte, sea $U$ un subespacio de $V$ que contiene a $S$. Sea $v \in \langle S \rangle$, entonces $v=a_1s_1+...+a_ns_n$, con $a_1,...,a_n \in K$ y $s_1,...,s_n \in S$, además como $S \subseteq U$ entonces $v=a_1s_1+a_2s_2+...+a_ns_n \in U$, pues los subespacios vectoriales son cerrados bajo la suma y bajo el producto por escalares. Por tanto tenemos que si $v \in \langle S \rangle$ entonces $v \in U$, así que $\langle S \rangle \subseteq U$.
\end{proof}

\begin{definition}
Sea $S \subseteq V$. Decimos que $S$ genera a $V$ si $\langle S \rangle = V$. También podemos decir que los elementos de $S$ generan a $V$.
\end{definition}

\subsection{Dependencia e independencia lineal.}

\begin{definition}
Sea $S=\{s_1,s_2,...,s_n\}\subseteq V$. Decimos que $S$ es linealmente dependiente si existe $s \in S$ tal que $s \in \langle S-\{s\} \rangle$.
\end{definition}

\begin{theorem}
Sea $S=\{s_1,s_2,...,s_n\}\subseteq V$. $S$ es linealmente dependiente si y solo si existen $a_1,a_2,...,a_n \in K$ tal que $a_1s_1+a_2s_2+...+a_ns_n=0_V$ y $a_1,a_2,...,a_n \in K$ no son todos cero.
\end{theorem}

\begin{proof}
$\Rightarrow$ Supongamos que $S$ es linealmente dependiente, entonces existe $s \in S$ tal que $s \in \langle S-\{ s \} \rangle$, por tanto existen $s_1,s_2,...,s_n \in S-\{s\}$ y los escalares $a_1,a_2,...,a_n \in K$ tales que $s=a_1s_1+a_2s_2+...+a_ns_n$. Al sumar $-s$ en ambos lados de la expresión anterior obtenemos $0_V=-s+a_1s_1+a_2s_2+...+a_ns_n$, con lo cual se garantiza que no todos los escalares que multiplican a los vectores son cero, pues $-1$ multiplica a $s$.\newline \newline
$\Leftarrow$ Supongamos que existen $a_1,a_2,...,a_n \in K$, no todos cero, tales que $a_1s_1+a_2s_2+...+a_ns_n=0_V$. Puesto que no todos los escalares son cero, supongamos sin perdida de generalidad que $a_1\neq 0$, por tanto podemos multiplicar en ambos lados de la igualdad anterior por el escalar $\dfrac{1}{a_1}$. En consecuencia obtenemos $s_1+\dfrac{a_2}{a_1}s_2+...+\dfrac{a_n}{a_1} s_n=0_V$. Luego, al sumar $-s_1$ y multiplicar por $-1$ en ambos lados nos queda que $s_1=\left(-\dfrac{a_2}{a_1}\right) s_2+...+\left( - \dfrac{a_n}{a_1}\right) s_n$, esto es, que $s_1 \in \langle S -\{ s_1 \} \rangle$. Por lo tanto $S$ es linealmente dependiente.
\end{proof}

\begin{definition}
Sea $S \subseteq V$. Decimos que $S$ es linealmente independiente si y solo si no es linealmente dependiente.
\end{definition}

Por la equivalencia lógica $(P \Leftrightarrow \exists x (Q \wedge S)) \Leftrightarrow (\neg P \Leftrightarrow \forall x (Q\Rightarrow \neg S))$, el teorema anterior es equivalente a la siguiente proposición que enunciaremos como corolario.

\begin{corollary}
Sea $S \subseteq V$. $S$ es linealmente independiente si y solo si para todo $a_1,a_2,...,a_n \in K$ tal que si $a_1s_1+a_2s_2+...+a_ns_n=0_V$ entonces $a_1,a_2,...,a_n$ son todos cero.
\end{corollary}

\begin{proof}
Se sigue del teorema anterior y de la equivalencia lógica $(P \Leftrightarrow \exists x (Q \wedge S)) \Leftrightarrow (\neg P \Leftrightarrow \forall x (Q\Rightarrow \neg S))$.
\end{proof}

\begin{proposition}
Si $S \subseteq V$ y $0_V \in S$, entonces $S$ es linealmente dependiente.
\end{proposition}

\begin{proof}

\end{proof}

\begin{theorem}
El conjunto $\emptyset$ es linealmente independiente
\end{theorem}

\begin{proof}
Supongamos que $\emptyset$ es linealmente dependiente, entonces existe $s \in \emptyset$ tal que $s \in \langle \emptyset-\{s\} \rangle$. Como $s \in \emptyset$ entonces por definición del conjunto vacío se cumple que $s\neq s$ lo cual es una contradicción. Por lo tanto el conjunto $\emptyset$ es linealmente independiente.
\end{proof}

\begin{lemma}
Si $V$ es un $K-$espacio vectorial y $S_1\subseteq S_2\subseteq V$, entonces $\langle S_1 \rangle \subseteq \langle S_2 \rangle$.
\end{lemma}

\begin{proof}

\end{proof}

\begin{theorem}
Sea $V$ un $K-$espacio vectorial y sean $S_1\subseteq S_2\subseteq V$. Si $S_1$ es linealmente dependiente entonces $S_2$ también lo es.
\end{theorem}

\begin{proof}
Supongamos que $S_1$ es linealmente dependiente, entonces existe $s \in S_1$ tal que $s \in \langle S_1-\{s\} \rangle$. Luego, como $S_1\subseteq S_2$ entonces $S_1-\{s\} \subseteq S_2-\{s \}$, y por el lema anterior $\langle S_1-\{s \} \rangle \subseteq \langle S_2-\{s \} \rangle$, por lo que $s \in \langle S_2-\{s\} \rangle$, luego $S_2$ es linealmente dependiente.
\end{proof}

\begin{corollary}
Sea $V$ un $K-$espacio vectorial y sean $S_1\subseteq S_2\subseteq V$. Si $S_2$ es linealmente independiente entonces $S_1$ también lo es.
\end{corollary}

\begin{proof}
La demostración se sigue de hacer la contrapositiva del teorema anterior.
\end{proof}

\subsection{Bases y dimensiones.}

\begin{definition}
Sea $\beta \subseteq V$. Decimos que $\beta$ es una base para $V$ si y solo si $\beta$ es linealmente independiente y $\langle \beta \rangle=V$.
\end{definition}

\begin{theorem}

Sea $V$ un espacio vectorial y $\beta = \{b_1, b_2,...,b_n\}$ un subconjunto de $V$. Luego $\beta$ es una base para $V$ si y sólo si cada vector $v \in V$ puede ser expresado de manera única como una combinación lineal de vectores de $\beta$, es decir, puede ser expresado de la forma $v = a_1 b_1 + a_2 b_2 + ...+ a_n b_n$, para escalares únicos $a_1, a_2, ..., a_n \in K$.

\end{theorem}

\begin{proof}

$\Rightarrow$ Supongamos que $\beta$ es una base para $V$. Sea $v \in V$, entonces $v \in \langle \beta \rangle$, así que existen $a_1, a_2, ..., a_n \in K$ tal que $v = a_1 b_1 + a_2 b_2 + ...+ a_n b_n$. Ahora, supongamos que también $v = c_1 b_1 + c_2 b_2 + ...+ c_n b_n$, con $c_1,c_2,...,c_n \in K$. Entonces es claro que $v-v=0_V=(a_1 - c_1)b_1+(a_2 -c_2)b_2 +...+(a_n -c_n)b_n$. Ya que $\beta$ es linealmente independiente, $a_1 -c_1=0, a_2 -c_2=0, ..., a_n -c_n=0$, en consecuencia $a_1=c_1, a_2 =c_2, ..., a_n =c_n$, por lo tanto la representación de $v$ como combinación lineal de $\beta$ es única.\newline

$\Leftarrow$ Supongamos que cada vector $v \in V$ puede ser expresado como una combinación lineal de vectores de $\beta$ con los escalares únicos $a_1, a_2, ..., a_n \in K$. Por lo tanto $\langle \beta \rangle=V$. Probemos ahora que $\beta$ es linealmente independiente. Tenemos que el elemento $0_V$ puede ser expresado como $0_V=a_1b_1+a_2b_2+...+a_nb_n$, y puesto que esta manera es única, se tiene que cada escalar $a_1, a_2, ..., a_n$ debe ser $0$, por lo tanto $\beta$ es linealmente independiente, y en consecuencia $\beta$ es una base.

\end{proof}

\begin{theorem}
Si $V$ es un espacio vectorial y $S \subseteq V$ tal que $S$ es finito y genera a $V$, entonces existe $S' \subseteq S$ tal que $S'$ es una base para $V$.

\end{theorem}

\begin{proof}
Si $S= \emptyset$ o $S=\{0_V\}$ entonces $V=\{0_V\}$ y como $\emptyset$ es subconjunto de cualquier conjunto, entonces $S$ es una base para $V$. De lo contrario, $V$ tendrá al menos un elemento $v_1$ no nulo. Nótese que $\{v_1\}$ es un conjunto linealmente independiente. Continúese, si es posible, escogiendo elementos $v_2,v_3,...,v_r \in V$ tales que $\{ v_1,v_2,v_3,...,v_r \}$ sea linealmente independiente. Puesto que $S$ es finito, se llegará al punto en el que $S'=\{v_1,v_2,v_3,...,v_r\}$ sea un subconjunto de $S$ linealmente independiente, de manera que al agregar otro delemento de $S$ a $S'$, éste sea linealmente dependiente. Demostremos ahora que $S'$ es una base para $V$. Como $S'$ es linealmente independiente, basta mostrar que es generador de $V$, pero como $\langle S \rangle=V$, es suficiente demostrar que $S \subseteq \langle S' \rangle$. Sea $v \in S$. Si $v \in S'$, entonces $v \in \langle S' \rangle$. Por otro lado, si $v$ no está en $S'$, la anterior construcción mostraría que $S' \cup \{v\}$ es linealmente dependiente. Así, $v \in \langle S' \rangle$, y por tanto $S \subseteq \langle S' \rangle$.
\end{proof}
\end{document}
